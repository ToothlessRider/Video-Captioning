# Video Captioning :video_camera:
Video Captioning :video_camera: is an encoder-decoder mode based on sequence to sequence learning. It takes a video :film_strip: as input and generates a caption :memo: describing the event in the video.

The importance of captioning :memo: lies in its ability to make video :movie_camera: more accessible in numerous ways. An automated video caption generator ğŸ¤– helps searching of videos in websites better. It can be used for clustering of videos based on their content easier.

## Table of Contents
1. Reason



## Reason
This project is something I've built as a part of my Deep-Learning ğŸ“š course as requested by our professor ğŸ‘¨â€ğŸ«, for us to familiarize ourselves with various concepts within the subject, which include manipulation of high-dimensional data ğŸ“Š (such as videos ğŸ¥) and extraction of information from them.


## References 
[Shreyaz-max Video captioning](https://github.com/Shreyz-max/Video-Captioning?tab=readme-ov-file#Inspiration)
[SV2T paper](https://arxiv.org/abs/1505.00487#)
[Keras Implementation by @alvinbhou](https://github.com/CryoliteZ/Video2Text)
[Intelligent Projects using Python by @santannupatanayak](https://github.com/PacktPublishing/Intelligent-Projects-Using-Python/blob/master/Chapter05)